op0: ExternKernelSchedulerNode(ExternKernelOut)
op0.writes = [StarDep(name='buf0', mode=None)]
op0.unmet_dependencies = []
op0.met_dependencies = [StarDep(name='arg0_1', mode=None), StarDep(name='arg1_1', mode=None)]
op0.outputs = [
    buf0: ExternKernelOut
    buf0.layout = FixedLayout('cuda', torch.float16, size=[8192, 1536], stride=[1536, 1])
    buf0.users = [
        NodeUser(node=SchedulerNode(name='op1'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op2'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op7'), can_inplace=False, is_weak=False),
    ]
]
op0.node.kernel = extern_kernels.mm


op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', c0, {c0: 4194304}, None)]
op1.unmet_dependencies = [   MemoryDep('buf0', 1572864*c0 + 32*c1 + 1536*c2 + c3, {c0: 8, c1: 16, c2: 1024, c3: 32}, None)]
op1.met_dependencies = [MemoryDep('arg2_1', 32*c1 + c3, {c0: 8, c1: 16, c2: 1024, c3: 32}, None)]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda', torch.float16, size=[8, 16, 1024, 32], stride=[524288, 32768, 32, 1])
    buf1.users = [NodeUser(node=ExternKernelSchedulerNode(name='op3'), can_inplace=False, is_weak=False)]
]
op1.group.device = cuda:0
op1.group.iteration = (4194304, 1)
op1.sizes = ([8, 16, 1024, 32], [])
buf0_layout = FixedLayout('cuda', torch.float16, size=[8192, 1536], stride=[1536, 1])
arg2_1_layout = FixedLayout('cuda', torch.float16, size=[1536], stride=[1])
buf1_layout = FixedLayout('cuda', torch.float16, size=[8, 16, 1024, 32], stride=[524288, 32768, 32, 1])
class op1_loop_body:
    var_ranges = {z0: 8, z1: 16, z2: 1024, z3: 32}
    index0 = 1572864*z0 + 32*z1 + 1536*z2 + z3
    index1 = 32*z1 + z3
    index2 = 524288*z0 + 32768*z1 + 32*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf0', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg2_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index2')
        store = ops.store('buf1', get_index_2, add, None)
        return store
op1 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 4194304
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x0 = xindex % 32
        x1 = (xindex // 32) % 1024
        x2 = (xindex // 32768) % 16
        x3 = (xindex // 524288)
        x4 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (32*x2) + (1536*x1) + (1572864*x3)), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (x0 + (32*x2)), None, eviction_policy='evict_last').to(tl.float32)
        tmp2 = tmp0 + tmp1
        tl.store(out_ptr0 + (x4), tmp2, None)


op2: SchedulerNode(ComputedBuffer)
op2.writes = [MemoryDep('buf2', c0, {c0: 4194304}, None)]
op2.unmet_dependencies = [   MemoryDep('buf0', 1572864*c0 + c1 + 1536*c2 + 512, {c0: 8, c1: 512, c2: 1024}, None)]
op2.met_dependencies = [MemoryDep('arg2_1', c1 + 512, {c0: 8, c1: 512}, None)]
op2.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda', torch.float16, size=[8, 16, 32, 1024], stride=[524288, 32768, 1024, 1])
    buf2.users = [NodeUser(node=ExternKernelSchedulerNode(name='op3'), can_inplace=False, is_weak=False)]
]
op2.group.device = cuda:0
op2.group.iteration = (4194304, 1)
op2.sizes = ([8, 512, 1024], [])
buf0_layout = FixedLayout('cuda', torch.float16, size=[8192, 1536], stride=[1536, 1])
arg2_1_layout = FixedLayout('cuda', torch.float16, size=[1536], stride=[1])
buf2_layout = FixedLayout('cuda', torch.float16, size=[8, 16, 32, 1024], stride=[524288, 32768, 1024, 1])
class op2_loop_body:
    var_ranges = {z0: 8, z1: 512, z2: 1024}
    index0 = 1572864*z0 + z1 + 1536*z2 + 512
    index1 = z1 + 512
    index2 = 524288*z0 + 1024*z1 + z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf0', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg2_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index2')
        store = ops.store('buf2', get_index_2, add, None)
        return store
op2 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4096, 1024], tile_hint=TileHint.DEFAULT,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
        ynumel = 4096
        xnumel = 1024
        yoffset = tl.program_id(1) * YBLOCK
        yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
        ymask = tl.full([XBLOCK, YBLOCK], True, tl.int1)
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = xindex < xnumel
        x2 = xindex
        y0 = yindex % 512
        y1 = (yindex // 512)
        y3 = yindex
        tmp0 = tl.load(in_ptr0 + (512 + y0 + (1536*x2) + (1572864*y1)), xmask, eviction_policy='evict_last').to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (512 + y0), None, eviction_policy='evict_last').to(tl.float32)
        tmp2 = tmp0 + tmp1
        tl.store(out_ptr0 + (x2 + (1024*y3)), tmp2, xmask)


op3: ExternKernelSchedulerNode(ExternKernelOut)
op3.writes = [StarDep(name='buf3', mode=None)]
op3.unmet_dependencies = [StarDep(name='buf1', mode=None), StarDep(name='buf2', mode=None)]
op3.met_dependencies = []
op3.outputs = [
    buf3: ExternKernelOut
    buf3.layout = FixedLayout('cuda', torch.float16, size=[128, 1024, 1024], stride=[1048576, 1024, 1])
    buf3.users = [
        NodeUser(node=SchedulerNode(name='op4'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op5'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op6'), can_inplace=True, is_weak=False),
    ]
]
op3.node.kernel = extern_kernels.bmm


op4: SchedulerNode(ComputedBuffer)
op4.writes = [MemoryDep('buf4', c0, {c0: 131072}, None)]
op4.unmet_dependencies = [MemoryDep('buf3', c0, {c0: 134217728}, None)]
op4.met_dependencies = [MemoryDep('arg3_1', 1048576*c0 + c2, {c0: 8, c1: 16, c2: 1048576}, None)]
op4.outputs = [
    buf4: ComputedBuffer
    buf4.layout = FixedLayout('cuda', torch.float32, size=[8, 16, 1024, 1], stride=[16384, 1024, 1, 131072])
    buf4.users = [
        NodeUser(node=SchedulerNode(name='op5'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op6'), can_inplace=False, is_weak=False),
    ]
]
op4.group.device = cuda:0
op4.group.iteration = (131072, 1024)
op4.sizes = ([8, 16, 1024], [1024])
buf3_layout = FixedLayout('cuda', torch.float16, size=[128, 1024, 1024], stride=[1048576, 1024, 1])
arg3_1_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1024], stride=[1048576, 1024, 1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[8, 16, 1024, 1], stride=[16384, 1024, 1, 131072])
class op4_loop_body:
    var_ranges = {z0: 8, z1: 16, z2: 1024, z3: 1024}
    index0 = 16777216*z0 + 1048576*z1 + 1024*z2 + z3
    index1 = 1048576*z0 + 1024*z2 + z3
    index2 = 16384*z0 + 1024*z1 + z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf3', get_index)
        constant = ops.constant(0.17677669529663687, torch.float16)
        mul = ops.mul(load, constant)
        to_dtype = ops.to_dtype(mul, torch.float32, src_dtype = torch.float16)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg3_1', get_index_1)
        constant_1 = ops.constant(1.0, torch.float32)
        sub = ops.sub(constant_1, load_1)
        constant_2 = ops.constant(10000.0, torch.float32)
        mul_1 = ops.mul(sub, constant_2)
        sub_1 = ops.sub(to_dtype, mul_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', sub_1)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf4', get_index_2, reduction)
        return store_reduction
op4 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[131072, 1024],
        reduction_hint=ReductionHint.DEFAULT,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp32', 2: '*fp32', 3: 'i32', 4: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 1, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 131072
        rnumel = 1024
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
        rbase = tl.arange(0, RBLOCK)[None, :]
        x4 = xindex
        x0 = xindex % 1024
        x2 = (xindex // 16384)
        _tmp11 = tl.full([XBLOCK, RBLOCK], float("-inf"), tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r3 = rindex
            tmp0 = tl.load(in_ptr0 + (r3 + (1024*x4)), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
            tmp4 = tl.load(in_ptr1 + (r3 + (1024*x0) + (1048576*x2)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.17677669529663687
            tmp2 = tmp0 * tmp1
            tmp3 = tmp2.to(tl.float32)
            tmp5 = 1.0
            tmp6 = tmp5 - tmp4
            tmp7 = 10000.0
            tmp8 = tmp6 * tmp7
            tmp9 = tmp3 - tmp8
            tmp10 = tl.broadcast_to(tmp9, [XBLOCK, RBLOCK])
            tmp12 = triton_helpers.maximum(_tmp11, tmp10)
            _tmp11 = tl.where(rmask, tmp12, _tmp11)
        tmp11 = triton_helpers.max2(_tmp11, 1)[:, None]
        tl.store(out_ptr0 + (x4), tmp11, None)


op5: SchedulerNode(ComputedBuffer)
op5.writes = [MemoryDep('buf5', c0, {c0: 131072}, None)]
op5.unmet_dependencies = 
    [   MemoryDep('buf3', c0, {c0: 134217728}, None),
        MemoryDep('buf4', c0, {c0: 131072}, None)]
op5.met_dependencies = [MemoryDep('arg3_1', 1048576*c0 + c2, {c0: 8, c1: 16, c2: 1048576}, None)]
op5.outputs = [
    buf5: ComputedBuffer
    buf5.layout = FixedLayout('cuda', torch.float32, size=[8, 16, 1024, 1], stride=[16384, 1024, 1, 131072])
    buf5.users = [NodeUser(node=SchedulerNode(name='op6'), can_inplace=False, is_weak=False)]
]
op5.group.device = cuda:0
op5.group.iteration = (131072, 1024)
op5.sizes = ([8, 16, 1024], [1024])
buf3_layout = FixedLayout('cuda', torch.float16, size=[128, 1024, 1024], stride=[1048576, 1024, 1])
arg3_1_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1024], stride=[1048576, 1024, 1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[8, 16, 1024, 1], stride=[16384, 1024, 1, 131072])
buf5_layout = FixedLayout('cuda', torch.float32, size=[8, 16, 1024, 1], stride=[16384, 1024, 1, 131072])
class op5_loop_body:
    var_ranges = {z0: 8, z1: 16, z2: 1024, z3: 1024}
    index0 = 16777216*z0 + 1048576*z1 + 1024*z2 + z3
    index1 = 1048576*z0 + 1024*z2 + z3
    index2 = 16384*z0 + 1024*z1 + z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf3', get_index)
        constant = ops.constant(0.17677669529663687, torch.float16)
        mul = ops.mul(load, constant)
        to_dtype = ops.to_dtype(mul, torch.float32, src_dtype = torch.float16)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg3_1', get_index_1)
        constant_1 = ops.constant(1.0, torch.float32)
        sub = ops.sub(constant_1, load_1)
        constant_2 = ops.constant(10000.0, torch.float32)
        mul_1 = ops.mul(sub, constant_2)
        sub_1 = ops.sub(to_dtype, mul_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('buf4', get_index_2)
        sub_2 = ops.sub(sub_1, load_2)
        exp = ops.exp(sub_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf5', get_index_3, reduction)
        return store_reduction
op5 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[131072, 1024],
        reduction_hint=ReductionHint.DEFAULT,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 3, 'num_reduction': 1, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 131072
        rnumel = 1024
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
        rbase = tl.arange(0, RBLOCK)[None, :]
        x4 = xindex
        x0 = xindex % 1024
        x2 = (xindex // 16384)
        tmp10 = tl.load(in_ptr2 + (x4), None, eviction_policy='evict_last')
        _tmp14 = tl.full([XBLOCK, RBLOCK], 0, tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r3 = rindex
            tmp0 = tl.load(in_ptr0 + (r3 + (1024*x4)), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
            tmp4 = tl.load(in_ptr1 + (r3 + (1024*x0) + (1048576*x2)), rmask, eviction_policy='evict_last', other=0.0)
            tmp1 = 0.17677669529663687
            tmp2 = tmp0 * tmp1
            tmp3 = tmp2.to(tl.float32)
            tmp5 = 1.0
            tmp6 = tmp5 - tmp4
            tmp7 = 10000.0
            tmp8 = tmp6 * tmp7
            tmp9 = tmp3 - tmp8
            tmp11 = tmp9 - tmp10
            tmp12 = tl_math.exp(tmp11)
            tmp13 = tl.broadcast_to(tmp12, [XBLOCK, RBLOCK])
            tmp15 = _tmp14 + tmp13
            _tmp14 = tl.where(rmask, tmp15, _tmp14)
        tmp14 = tl.sum(_tmp14, 1)[:, None]
        tl.store(out_ptr0 + (x4), tmp14, None)


op6: SchedulerNode(ComputedBuffer)
op6.writes = [MemoryDep('buf6', c0, {c0: 134217728}, None)]
op6.unmet_dependencies = 
    [   MemoryDep('buf3', c0, {c0: 134217728}, None),
        MemoryDep('buf4', c0, {c0: 131072}, None),
        MemoryDep('buf5', c0, {c0: 131072}, None)]
op6.met_dependencies = [MemoryDep('arg3_1', 1048576*c0 + c2, {c0: 8, c1: 16, c2: 1048576}, None)]
op6.outputs = [
    buf6: ComputedBuffer
    buf6.layout = FixedLayout('cuda', torch.float16, size=[8, 16, 1024, 1024], stride=[16777216, 1048576, 1024, 1])
    buf6.users = [NodeUser(node=ExternKernelSchedulerNode(name='op8'), can_inplace=False, is_weak=False)]
]
op6.group.device = cuda:0
op6.group.iteration = (134217728, 1)
op6.sizes = ([8, 16, 1024, 1024], [])
buf3_layout = FixedLayout('cuda', torch.float16, size=[128, 1024, 1024], stride=[1048576, 1024, 1])
arg3_1_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1024], stride=[1048576, 1024, 1])
buf4_layout = FixedLayout('cuda', torch.float32, size=[8, 16, 1024, 1], stride=[16384, 1024, 1, 131072])
buf5_layout = FixedLayout('cuda', torch.float32, size=[8, 16, 1024, 1], stride=[16384, 1024, 1, 131072])
buf6_layout = FixedLayout('cuda', torch.float16, size=[8, 16, 1024, 1024], stride=[16777216, 1048576, 1024, 1])
class op6_loop_body:
    var_ranges = {z0: 8, z1: 16, z2: 1024, z3: 1024}
    index0 = 16777216*z0 + 1048576*z1 + 1024*z2 + z3
    index1 = 1048576*z0 + 1024*z2 + z3
    index2 = 16384*z0 + 1024*z1 + z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf3', get_index)
        constant = ops.constant(0.17677669529663687, torch.float16)
        mul = ops.mul(load, constant)
        to_dtype = ops.to_dtype(mul, torch.float32, src_dtype = torch.float16)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg3_1', get_index_1)
        constant_1 = ops.constant(1.0, torch.float32)
        sub = ops.sub(constant_1, load_1)
        constant_2 = ops.constant(10000.0, torch.float32)
        mul_1 = ops.mul(sub, constant_2)
        sub_1 = ops.sub(to_dtype, mul_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('buf4', get_index_2)
        sub_2 = ops.sub(sub_1, load_2)
        exp = ops.exp(sub_2)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('buf5', get_index_3)
        truediv = ops.truediv(exp, load_3)
        to_dtype_1 = ops.to_dtype(truediv, torch.float16, src_dtype = torch.float32)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf6', get_index_4, to_dtype_1, None)
        return store
op6 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[134217728], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp16', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 4, 'num_reduction': 0, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 134217728
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x4 = xindex
        x3 = (xindex // 16777216)
        x5 = xindex % 1048576
        x6 = (xindex // 1024)
        tmp0 = tl.load(in_ptr0 + (x4), None).to(tl.float32)
        tmp4 = tl.load(in_ptr1 + (x5 + (1048576*x3)), None, eviction_policy='evict_last')
        tmp10 = tl.load(in_ptr2 + (x6), None, eviction_policy='evict_last')
        tmp13 = tl.load(in_ptr3 + (x6), None, eviction_policy='evict_last')
        tmp1 = 0.17677669529663687
        tmp2 = tmp0 * tmp1
        tmp3 = tmp2.to(tl.float32)
        tmp5 = 1.0
        tmp6 = tmp5 - tmp4
        tmp7 = 10000.0
        tmp8 = tmp6 * tmp7
        tmp9 = tmp3 - tmp8
        tmp11 = tmp9 - tmp10
        tmp12 = tl_math.exp(tmp11)
        tmp14 = tmp12 / tmp13
        tmp15 = tmp14.to(tl.float32)
        tl.store(out_ptr0 + (x4), tmp15, None)


op7: SchedulerNode(ComputedBuffer)
op7.writes = [MemoryDep('buf7', c0, {c0: 4194304}, None)]
op7.unmet_dependencies = [   MemoryDep('buf0', 1572864*c0 + 32*c1 + 1536*c2 + c3 + 1024, {c0: 8, c1: 16, c2: 1024, c3: 32}, None)]
op7.met_dependencies = [   MemoryDep('arg2_1', 32*c1 + c3 + 1024, {c0: 8, c1: 16, c2: 1024, c3: 32}, None)]
op7.outputs = [
    buf7: ComputedBuffer
    buf7.layout = FixedLayout('cuda', torch.float16, size=[8, 16, 1024, 32], stride=[524288, 32768, 32, 1])
    buf7.users = [NodeUser(node=ExternKernelSchedulerNode(name='op8'), can_inplace=False, is_weak=False)]
]
op7.group.device = cuda:0
op7.group.iteration = (4194304, 1)
op7.sizes = ([8, 16, 1024, 32], [])
buf0_layout = FixedLayout('cuda', torch.float16, size=[8192, 1536], stride=[1536, 1])
arg2_1_layout = FixedLayout('cuda', torch.float16, size=[1536], stride=[1])
buf7_layout = FixedLayout('cuda', torch.float16, size=[8, 16, 1024, 32], stride=[524288, 32768, 32, 1])
class op7_loop_body:
    var_ranges = {z0: 8, z1: 16, z2: 1024, z3: 32}
    index0 = 1572864*z0 + 32*z1 + 1536*z2 + z3 + 1024
    index1 = 32*z1 + z3 + 1024
    index2 = 524288*z0 + 32768*z1 + 32*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf0', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg2_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index2')
        store = ops.store('buf7', get_index_2, add, None)
        return store
op7 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 4194304
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x0 = xindex % 32
        x1 = (xindex // 32) % 1024
        x2 = (xindex // 32768) % 16
        x3 = (xindex // 524288)
        x4 = xindex
        tmp0 = tl.load(in_ptr0 + (1024 + x0 + (32*x2) + (1536*x1) + (1572864*x3)), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (1024 + x0 + (32*x2)), None, eviction_policy='evict_last').to(tl.float32)
        tmp2 = tmp0 + tmp1
        tl.store(out_ptr0 + (x4), tmp2, None)


op8: ExternKernelSchedulerNode(ExternKernelOut)
op8.writes = [StarDep(name='buf8', mode=None)]
op8.unmet_dependencies = [StarDep(name='buf6', mode=None), StarDep(name='buf7', mode=None)]
op8.met_dependencies = []
op8.outputs = [
    buf8: ExternKernelOut
    buf8.layout = FixedLayout('cuda', torch.float16, size=[128, 1024, 32], stride=[32768, 32, 1])
    buf8.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=False, is_weak=False)]
]
op8.node.kernel = extern_kernels.bmm


op9: SchedulerNode(ComputedBuffer)
op9.writes = [MemoryDep('buf9', c0, {c0: 4194304}, None)]
op9.unmet_dependencies = [   MemoryDep('buf8', 524288*c0 + 32*c1 + 32768*c2 + c3, {c0: 8, c1: 1024, c2: 16, c3: 32}, None)]
op9.met_dependencies = []
op9.outputs = [
    buf9: ComputedBuffer
    buf9.layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 16, 32], stride=[524288, 512, 32, 1])
    buf9.users = [NodeUser(node=ExternKernelSchedulerNode(name='op10'), can_inplace=False, is_weak=False)]
]
op9.group.device = cuda:0
op9.group.iteration = (4194304, 1)
op9.sizes = ([8, 1024, 16, 32], [])
buf8_layout = FixedLayout('cuda', torch.float16, size=[128, 1024, 32], stride=[32768, 32, 1])
buf9_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 16, 32], stride=[524288, 512, 32, 1])
class op9_loop_body:
    var_ranges = {z0: 8, z1: 1024, z2: 16, z3: 32}
    index0 = 524288*z0 + 32*z1 + 32768*z2 + z3
    index1 = 524288*z0 + 512*z1 + 32*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf8', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf9', get_index_1, load, None)
        return store
op9 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 4194304
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x0 = xindex % 32
        x1 = (xindex // 32) % 16
        x2 = (xindex // 512) % 1024
        x3 = (xindex // 524288)
        x4 = xindex
        tmp0 = tl.load(in_ptr0 + (x0 + (32*x2) + (32768*x1) + (524288*x3)), None).to(tl.float32)
        tl.store(out_ptr0 + (x4), tmp0, None)


op10: ExternKernelSchedulerNode(ExternKernelOut)
op10.writes = [StarDep(name='buf10', mode=None)]
op10.unmet_dependencies = [StarDep(name='buf9', mode=None)]
op10.met_dependencies = [StarDep(name='arg4_1', mode=None)]
op10.outputs = [
    buf10: ExternKernelOut
    buf10.layout = FixedLayout('cuda', torch.float16, size=[8192, 512], stride=[512, 1])
    buf10.users = [
        NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op12'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op13'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op14'), can_inplace=True, is_weak=False),
    ]
]
op10.node.kernel = extern_kernels.mm


op11: SchedulerNode(ComputedBuffer)
op11.writes = [MemoryDep('buf11', c0, {c0: 8192}, None)]
op11.unmet_dependencies = [MemoryDep('buf10', c0, {c0: 4194304}, None)]
op11.met_dependencies = 
    [   MemoryDep('arg0_1', c0, {c0: 4194304}, None),
        MemoryDep('arg5_1', c1, {c0: 8192, c1: 512}, None)]
op11.outputs = [
    buf11: ComputedBuffer
    buf11.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
    buf11.users = [NodeUser(node=SchedulerNode(name='op14'), can_inplace=False, is_weak=False)]
]
op11.group.device = cuda:0
op11.group.iteration = (8192, 512)
op11.sizes = ([8192], [512])
buf10_layout = FixedLayout('cuda', torch.float16, size=[8192, 512], stride=[512, 1])
arg5_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
arg0_1_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
class op11_loop_body:
    var_ranges = {z0: 8192, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    index2 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf10', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg5_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('arg0_1', get_index_2)
        add_1 = ops.add(add, load_2)
        to_dtype = ops.to_dtype(add_1, torch.float32, src_dtype = torch.float16)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', to_dtype)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf11', get_index_3, getitem)
        return store_reduction
op11 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[8192, 512],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': True, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel):
        xnumel = 8192
        XBLOCK: tl.constexpr = 1
        rnumel = 512
        RBLOCK: tl.constexpr = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = tl.full([1], xoffset, tl.int32)
        xmask = tl.full([RBLOCK], True, tl.int1)
        rindex = tl.arange(0, RBLOCK)[:]
        roffset = 0
        rmask = tl.full([RBLOCK], True, tl.int1)
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (r1 + (512*x0)), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (r1), None, eviction_policy='evict_last').to(tl.float32)
        tmp3 = tl.load(in_ptr2 + (r1 + (512*x0)), None).to(tl.float32)
        tmp2 = tmp0 + tmp1
        tmp4 = tmp2 + tmp3
        tmp5 = tmp4.to(tl.float32)
        tmp6 = tl.broadcast_to(tmp5, [RBLOCK])
        tmp8 = tl.broadcast_to(tmp6, [RBLOCK])
        tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp8, 0))
        tmp11 = tl.full([1], 512, tl.int32)
        tmp12 = tmp11.to(tl.float32)
        tmp13 = tmp10 / tmp12
        tmp14 = tmp6 - tmp13
        tmp15 = tmp14 * tmp14
        tmp16 = tl.broadcast_to(tmp15, [RBLOCK])
        tmp18 = triton_helpers.promote_to_tensor(tl.sum(tmp16, 0))
        tl.store(out_ptr0 + (x0), tmp13, None)


op12: SchedulerNode(ComputedBuffer)
op12.writes = [MemoryDep('buf12', c0, {c0: 8192}, None)]
op12.unmet_dependencies = [MemoryDep('buf10', c0, {c0: 4194304}, None)]
op12.met_dependencies = 
    [   MemoryDep('arg0_1', c0, {c0: 4194304}, None),
        MemoryDep('arg5_1', c1, {c0: 8192, c1: 512}, None)]
op12.outputs = [
    buf12: ComputedBuffer
    buf12.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
    buf12.users = [NodeUser(node=SchedulerNode(name='op14'), can_inplace=False, is_weak=False)]
]
op12.group.device = cuda:0
op12.group.iteration = (8192, 512)
op12.sizes = ([8192], [512])
buf10_layout = FixedLayout('cuda', torch.float16, size=[8192, 512], stride=[512, 1])
arg5_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
arg0_1_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
buf12_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
class op12_loop_body:
    var_ranges = {z0: 8192, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    index2 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf10', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg5_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('arg0_1', get_index_2)
        add_1 = ops.add(add, load_2)
        to_dtype = ops.to_dtype(add_1, torch.float32, src_dtype = torch.float16)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', to_dtype)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf12', get_index_3, getitem_1)
        return store_reduction
op12 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[8192, 512],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': True, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel):
        xnumel = 8192
        XBLOCK: tl.constexpr = 1
        rnumel = 512
        RBLOCK: tl.constexpr = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = tl.full([1], xoffset, tl.int32)
        xmask = tl.full([RBLOCK], True, tl.int1)
        rindex = tl.arange(0, RBLOCK)[:]
        roffset = 0
        rmask = tl.full([RBLOCK], True, tl.int1)
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (r1 + (512*x0)), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (r1), None, eviction_policy='evict_last').to(tl.float32)
        tmp3 = tl.load(in_ptr2 + (r1 + (512*x0)), None).to(tl.float32)
        tmp2 = tmp0 + tmp1
        tmp4 = tmp2 + tmp3
        tmp5 = tmp4.to(tl.float32)
        tmp6 = tl.broadcast_to(tmp5, [RBLOCK])
        tmp8 = tl.broadcast_to(tmp6, [RBLOCK])
        tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp8, 0))
        tmp11 = tl.full([1], 512, tl.int32)
        tmp12 = tmp11.to(tl.float32)
        tmp13 = tmp10 / tmp12
        tmp14 = tmp6 - tmp13
        tmp15 = tmp14 * tmp14
        tmp16 = tl.broadcast_to(tmp15, [RBLOCK])
        tmp18 = triton_helpers.promote_to_tensor(tl.sum(tmp16, 0))
        tl.store(out_ptr0 + (x0), tmp18, None)


op14: SchedulerNode(ComputedBuffer)
op14.writes = [MemoryDep('buf14', c0, {c0: 4194304}, None)]
op14.unmet_dependencies = 
    [   MemoryDep('buf10', c0, {c0: 4194304}, None),
        MemoryDep('buf11', c0, {c0: 8192}, None),
        MemoryDep('buf12', c0, {c0: 8192}, None)]
op14.met_dependencies = 
    [   MemoryDep('arg0_1', c0, {c0: 4194304}, None),
        MemoryDep('arg5_1', c1, {c0: 8192, c1: 512}, None),
        MemoryDep('arg6_1', c1, {c0: 8192, c1: 512}, None),
        MemoryDep('arg7_1', c1, {c0: 8192, c1: 512}, None)]
op14.outputs = [
    buf14: ComputedBuffer
    buf14.layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
    buf14.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op15'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op18'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op20'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op21'), can_inplace=True, is_weak=False),
    ]
]
op14.group.device = cuda:0
op14.group.iteration = (4194304, 1)
op14.sizes = ([8192, 512], [])
buf10_layout = FixedLayout('cuda', torch.float16, size=[8192, 512], stride=[512, 1])
arg5_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
arg0_1_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
buf12_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
arg7_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
arg6_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
buf14_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
class op14_loop_body:
    var_ranges = {z0: 8192, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    index2 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf10', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg5_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('arg0_1', get_index_2)
        add_1 = ops.add(add, load_2)
        to_dtype = ops.to_dtype(add_1, torch.float32, src_dtype = torch.float16)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('buf11', get_index_3)
        sub = ops.sub(to_dtype, load_3)
        get_index_4 = self.get_index('index2')
        load_4 = ops.load('buf12', get_index_4)
        constant = ops.constant(512.0, torch.float32)
        truediv = ops.truediv(load_4, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add_2 = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add_2)
        mul = ops.mul(sub, rsqrt)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('arg7_1', get_index_5)
        to_dtype_1 = ops.to_dtype(load_5, torch.float32, src_dtype = torch.float16)
        mul_1 = ops.mul(mul, to_dtype_1)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('arg6_1', get_index_6)
        to_dtype_2 = ops.to_dtype(load_6, torch.float32, src_dtype = torch.float16)
        add_3 = ops.add(mul_1, to_dtype_2)
        to_dtype_3 = ops.to_dtype(add_3, torch.float16, src_dtype = torch.float32)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf14', get_index_7, to_dtype_3, None)
        return store
op14 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: '*fp32', 4: '*fp32', 5: '*fp16', 6: '*fp16', 7: '*fp16', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 4194304
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x2 = xindex
        x0 = xindex % 512
        x1 = (xindex // 512)
        tmp0 = tl.load(in_ptr0 + (x2), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last').to(tl.float32)
        tmp3 = tl.load(in_ptr2 + (x2), None).to(tl.float32)
        tmp6 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
        tmp15 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last').to(tl.float32)
        tmp18 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last').to(tl.float32)
        tmp2 = tmp0 + tmp1
        tmp4 = tmp2 + tmp3
        tmp5 = tmp4.to(tl.float32)
        tmp7 = tmp5 - tmp6
        tmp9 = 512.0
        tmp10 = tmp8 / tmp9
        tmp11 = 1e-05
        tmp12 = tmp10 + tmp11
        tmp13 = libdevice.rsqrt(tmp12)
        tmp14 = tmp7 * tmp13
        tmp16 = tmp15.to(tl.float32)
        tmp17 = tmp14 * tmp16
        tmp19 = tmp18.to(tl.float32)
        tmp20 = tmp17 + tmp19
        tmp21 = tmp20.to(tl.float32)
        tl.store(out_ptr0 + (x2), tmp21, None)


op15: ExternKernelSchedulerNode(ExternKernelOut)
op15.writes = [StarDep(name='buf15', mode=None)]
op15.unmet_dependencies = [StarDep(name='buf14', mode=None)]
op15.met_dependencies = [StarDep(name='arg8_1', mode=None)]
op15.outputs = [
    buf15: ExternKernelOut
    buf15.layout = FixedLayout('cuda', torch.float16, size=[8192, 2048], stride=[2048, 1])
    buf15.users = [NodeUser(node=SchedulerNode(name='op16'), can_inplace=True, is_weak=False)]
]
op15.node.kernel = extern_kernels.mm


op16: SchedulerNode(ComputedBuffer)
op16.writes = [MemoryDep('buf16', c0, {c0: 16777216}, None)]
op16.unmet_dependencies = [MemoryDep('buf15', c0, {c0: 16777216}, None)]
op16.met_dependencies = [MemoryDep('arg9_1', c1, {c0: 8192, c1: 2048}, None)]
op16.outputs = [
    buf16: ComputedBuffer
    buf16.layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 2048], stride=[2097152, 2048, 1])
    buf16.users = [NodeUser(node=ExternKernelSchedulerNode(name='op17'), can_inplace=False, is_weak=False)]
]
op16.group.device = cuda:0
op16.group.iteration = (16777216, 1)
op16.sizes = ([8192, 2048], [])
buf15_layout = FixedLayout('cuda', torch.float16, size=[8192, 2048], stride=[2048, 1])
arg9_1_layout = FixedLayout('cuda', torch.float16, size=[2048], stride=[1])
buf16_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 2048], stride=[2097152, 2048, 1])
class op16_loop_body:
    var_ranges = {z0: 8192, z1: 2048}
    index0 = 2048*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf15', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg9_1', get_index_1)
        add = ops.add(load, load_1)
        to_dtype = ops.to_dtype(add, torch.float32, src_dtype = torch.float16)
        constant = ops.constant(0.5, torch.float32)
        mul = ops.mul(to_dtype, constant)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf15', get_index_2)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg9_1', get_index_3)
        add_1 = ops.add(load_2, load_3)
        to_dtype_1 = ops.to_dtype(add_1, torch.float32, src_dtype = torch.float16)
        constant_1 = ops.constant(0.7071067811865476, torch.float32)
        mul_1 = ops.mul(to_dtype_1, constant_1)
        erf = ops.erf(mul_1)
        constant_2 = ops.constant(1.0, torch.float32)
        add_2 = ops.add(erf, constant_2)
        mul_2 = ops.mul(mul, add_2)
        to_dtype_2 = ops.to_dtype(mul_2, torch.float16, src_dtype = torch.float32)
        get_index_4 = self.get_index('index0')
        store = ops.store('buf16', get_index_4, to_dtype_2, None)
        return store
op16 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[16777216], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_out_ptr0, in_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 16777216
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x2 = xindex
        x0 = xindex % 2048
        tmp0 = tl.load(in_out_ptr0 + (x2), None).to(tl.float32)
        tmp1 = tl.load(in_ptr0 + (x0), None, eviction_policy='evict_last').to(tl.float32)
        tmp2 = tmp0 + tmp1
        tmp3 = tmp2.to(tl.float32)
        tmp4 = 0.5
        tmp5 = tmp3 * tmp4
        tmp6 = 0.7071067811865476
        tmp7 = tmp3 * tmp6
        tmp8 = libdevice.erf(tmp7)
        tmp9 = 1.0
        tmp10 = tmp8 + tmp9
        tmp11 = tmp5 * tmp10
        tmp12 = tmp11.to(tl.float32)
        tl.store(in_out_ptr0 + (x2), tmp12, None)


op17: ExternKernelSchedulerNode(ExternKernelOut)
op17.writes = [StarDep(name='buf17', mode=None)]
op17.unmet_dependencies = [StarDep(name='buf16', mode=None)]
op17.met_dependencies = [StarDep(name='arg10_1', mode=None)]
op17.outputs = [
    buf17: ExternKernelOut
    buf17.layout = FixedLayout('cuda', torch.float16, size=[8192, 512], stride=[512, 1])
    buf17.users = [
        NodeUser(node=SchedulerNode(name='op18'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op20'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op21'), can_inplace=True, is_weak=False),
    ]
]
op17.node.kernel = extern_kernels.mm


op18: SchedulerNode(ComputedBuffer)
op18.writes = [MemoryDep('buf18', c0, {c0: 8192}, None)]
op18.unmet_dependencies = 
    [   MemoryDep('buf14', c0, {c0: 4194304}, None),
        MemoryDep('buf17', c0, {c0: 4194304}, None)]
op18.met_dependencies = [MemoryDep('arg11_1', c1, {c0: 8192, c1: 512}, None)]
op18.outputs = [
    buf18: ComputedBuffer
    buf18.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
    buf18.users = [NodeUser(node=SchedulerNode(name='op21'), can_inplace=False, is_weak=False)]
]
op18.group.device = cuda:0
op18.group.iteration = (8192, 512)
op18.sizes = ([8192], [512])
buf17_layout = FixedLayout('cuda', torch.float16, size=[8192, 512], stride=[512, 1])
arg11_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
buf14_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
class op18_loop_body:
    var_ranges = {z0: 8192, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    index2 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf17', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg11_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf14', get_index_2)
        add_1 = ops.add(add, load_2)
        to_dtype = ops.to_dtype(add_1, torch.float32, src_dtype = torch.float16)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', to_dtype)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf18', get_index_3, getitem)
        return store_reduction
op18 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[8192, 512],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': True, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel):
        xnumel = 8192
        XBLOCK: tl.constexpr = 1
        rnumel = 512
        RBLOCK: tl.constexpr = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = tl.full([1], xoffset, tl.int32)
        xmask = tl.full([RBLOCK], True, tl.int1)
        rindex = tl.arange(0, RBLOCK)[:]
        roffset = 0
        rmask = tl.full([RBLOCK], True, tl.int1)
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (r1 + (512*x0)), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (r1), None, eviction_policy='evict_last').to(tl.float32)
        tmp3 = tl.load(in_ptr2 + (r1 + (512*x0)), None).to(tl.float32)
        tmp2 = tmp0 + tmp1
        tmp4 = tmp2 + tmp3
        tmp5 = tmp4.to(tl.float32)
        tmp6 = tl.broadcast_to(tmp5, [RBLOCK])
        tmp8 = tl.broadcast_to(tmp6, [RBLOCK])
        tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp8, 0))
        tmp11 = tl.full([1], 512, tl.int32)
        tmp12 = tmp11.to(tl.float32)
        tmp13 = tmp10 / tmp12
        tmp14 = tmp6 - tmp13
        tmp15 = tmp14 * tmp14
        tmp16 = tl.broadcast_to(tmp15, [RBLOCK])
        tmp18 = triton_helpers.promote_to_tensor(tl.sum(tmp16, 0))
        tl.store(out_ptr0 + (x0), tmp13, None)


op19: SchedulerNode(ComputedBuffer)
op19.writes = [MemoryDep('buf19', c0, {c0: 8192}, None)]
op19.unmet_dependencies = 
    [   MemoryDep('buf14', c0, {c0: 4194304}, None),
        MemoryDep('buf17', c0, {c0: 4194304}, None)]
op19.met_dependencies = [MemoryDep('arg11_1', c1, {c0: 8192, c1: 512}, None)]
op19.outputs = [
    buf19: ComputedBuffer
    buf19.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
    buf19.users = [NodeUser(node=SchedulerNode(name='op21'), can_inplace=False, is_weak=False)]
]
op19.group.device = cuda:0
op19.group.iteration = (8192, 512)
op19.sizes = ([8192], [512])
buf17_layout = FixedLayout('cuda', torch.float16, size=[8192, 512], stride=[512, 1])
arg11_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
buf14_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
buf19_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
class op19_loop_body:
    var_ranges = {z0: 8192, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    index2 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf17', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg11_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf14', get_index_2)
        add_1 = ops.add(add, load_2)
        to_dtype = ops.to_dtype(add_1, torch.float32, src_dtype = torch.float16)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', to_dtype)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_3 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf19', get_index_3, getitem_1)
        return store_reduction
op19 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.persistent_reduction(
        size_hints=[8192, 512],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': True, 'num_load': 3, 'num_reduction': 3, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, rnumel):
        xnumel = 8192
        XBLOCK: tl.constexpr = 1
        rnumel = 512
        RBLOCK: tl.constexpr = 512
        xoffset = tl.program_id(0) * XBLOCK
        xindex = tl.full([1], xoffset, tl.int32)
        xmask = tl.full([RBLOCK], True, tl.int1)
        rindex = tl.arange(0, RBLOCK)[:]
        roffset = 0
        rmask = tl.full([RBLOCK], True, tl.int1)
        r1 = rindex
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (r1 + (512*x0)), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (r1), None, eviction_policy='evict_last').to(tl.float32)
        tmp3 = tl.load(in_ptr2 + (r1 + (512*x0)), None).to(tl.float32)
        tmp2 = tmp0 + tmp1
        tmp4 = tmp2 + tmp3
        tmp5 = tmp4.to(tl.float32)
        tmp6 = tl.broadcast_to(tmp5, [RBLOCK])
        tmp8 = tl.broadcast_to(tmp6, [RBLOCK])
        tmp10 = triton_helpers.promote_to_tensor(tl.sum(tmp8, 0))
        tmp11 = tl.full([1], 512, tl.int32)
        tmp12 = tmp11.to(tl.float32)
        tmp13 = tmp10 / tmp12
        tmp14 = tmp6 - tmp13
        tmp15 = tmp14 * tmp14
        tmp16 = tl.broadcast_to(tmp15, [RBLOCK])
        tmp18 = triton_helpers.promote_to_tensor(tl.sum(tmp16, 0))
        tl.store(out_ptr0 + (x0), tmp18, None)


op21: SchedulerNode(ComputedBuffer)
op21.writes = [MemoryDep('buf21', c0, {c0: 4194304}, None)]
op21.unmet_dependencies = 
    [   MemoryDep('buf14', c0, {c0: 4194304}, None),
        MemoryDep('buf17', c0, {c0: 4194304}, None),
        MemoryDep('buf18', c0, {c0: 8192}, None),
        MemoryDep('buf19', c0, {c0: 8192}, None)]
op21.met_dependencies = 
    [   MemoryDep('arg11_1', c1, {c0: 8192, c1: 512}, None),
        MemoryDep('arg12_1', c1, {c0: 8192, c1: 512}, None),
        MemoryDep('arg13_1', c1, {c0: 8192, c1: 512}, None)]
op21.outputs = [
    buf21: ComputedBuffer
    buf21.layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
    buf21.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op21.group.device = cuda:0
op21.group.iteration = (4194304, 1)
op21.sizes = ([8192, 512], [])
buf17_layout = FixedLayout('cuda', torch.float16, size=[8192, 512], stride=[512, 1])
arg11_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
buf14_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
buf18_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
buf19_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1], stride=[1024, 1, 8192])
arg13_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
arg12_1_layout = FixedLayout('cuda', torch.float16, size=[512], stride=[1])
buf21_layout = FixedLayout('cuda', torch.float16, size=[8, 1024, 512], stride=[524288, 512, 1])
class op21_loop_body:
    var_ranges = {z0: 8192, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    index2 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf17', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg11_1', get_index_1)
        add = ops.add(load, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf14', get_index_2)
        add_1 = ops.add(add, load_2)
        to_dtype = ops.to_dtype(add_1, torch.float32, src_dtype = torch.float16)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('buf18', get_index_3)
        sub = ops.sub(to_dtype, load_3)
        get_index_4 = self.get_index('index2')
        load_4 = ops.load('buf19', get_index_4)
        constant = ops.constant(512.0, torch.float32)
        truediv = ops.truediv(load_4, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add_2 = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add_2)
        mul = ops.mul(sub, rsqrt)
        get_index_5 = self.get_index('index1')
        load_5 = ops.load('arg13_1', get_index_5)
        to_dtype_1 = ops.to_dtype(load_5, torch.float32, src_dtype = torch.float16)
        mul_1 = ops.mul(mul, to_dtype_1)
        get_index_6 = self.get_index('index1')
        load_6 = ops.load('arg12_1', get_index_6)
        to_dtype_2 = ops.to_dtype(load_6, torch.float32, src_dtype = torch.float16)
        add_3 = ops.add(mul_1, to_dtype_2)
        to_dtype_3 = ops.to_dtype(add_3, torch.float16, src_dtype = torch.float32)
        get_index_7 = self.get_index('index0')
        store = ops.store('buf21', get_index_7, to_dtype_3, None)
        return store
op21 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[4194304], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp16', 2: '*fp16', 3: '*fp32', 4: '*fp32', 5: '*fp16', 6: '*fp16', 7: '*fp16', 8: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=108), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 7, 'num_reduction': 0, 'backend_hash': 'EE52B3E22FE0E1CBEBB76214115F53FF3B61A525BEEA2EA79A4DAA2457974610', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 4194304
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x2 = xindex
        x0 = xindex % 512
        x1 = (xindex // 512)
        tmp0 = tl.load(in_ptr0 + (x2), None).to(tl.float32)
        tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last').to(tl.float32)
        tmp3 = tl.load(in_ptr2 + (x2), None).to(tl.float32)
        tmp6 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last')
        tmp8 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last')
        tmp15 = tl.load(in_ptr5 + (x0), None, eviction_policy='evict_last').to(tl.float32)
        tmp18 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last').to(tl.float32)
        tmp2 = tmp0 + tmp1
        tmp4 = tmp2 + tmp3
        tmp5 = tmp4.to(tl.float32)
        tmp7 = tmp5 - tmp6
        tmp9 = 512.0
        tmp10 = tmp8 / tmp9
        tmp11 = 1e-05
        tmp12 = tmp10 + tmp11
        tmp13 = libdevice.rsqrt(tmp12)
        tmp14 = tmp7 * tmp13
        tmp16 = tmp15.to(tl.float32)
        tmp17 = tmp14 * tmp16
        tmp19 = tmp18.to(tl.float32)
        tmp20 = tmp17 + tmp19
        tmp21 = tmp20.to(tl.float32)
        tl.store(out_ptr0 + (x2), tmp21, None)


